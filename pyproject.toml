[project]
name = "llm-api"
version = "0.1.0"
description = "A fast CPU-based API for LLMs"
requires-python = ">=3.13.7, <3.14"
dependencies = [
    "ctranslate2>=4.6.3",
    "granian>=2.6.1",
    "jinja2>=3.1.6",
    "litestar>=2.19.0",
    "msgspec>=0.20.0",
    "pydantic-settings>=2.12.0",
    "transformers>=4.57.5",
    "uvloop>=0.22.1",
    "picologging>=0.9.3; python_version < '3.13'",
    "aiohttp>=3.13.3",
    "opentelemetry-instrumentation-asgi>=0.58b0",
    "opentelemetry-exporter-otlp-proto-http>=1.39.1",
    "torch>=2.9.1",
    "fast-query-parsers>=1.0.3",
    "opentelemetry-instrumentation-system-metrics>=0.59b0",
]

[project.optional-dependencies]
cuda = ["nvidia-cublas-cu12>=12.0.1.189"]

[dependency-groups]
dev = ["nodejs-wheel-binaries>=24.13.0", "pyright>=1.1.408", "ruff>=0.14.13"]

[build-system]
requires = ["uv_build"]
build-backend = "uv_build"

[tool.uv.build-backend]
module-root = ""
module-name = "server"
source-exclude = ["**/typings"]

[project.scripts]
llm-api = "server:main"

[tool.ruff]
line-length = 120

[tool.ruff.lint]
select = ["ALL"]
ignore = ["D", "TC", "PLC0414", "INP001", "S104", "PYI001", "COM812", "PLR0913"]

[tool.ruff.lint.flake8-annotations]
suppress-dummy-args = true

[tool.pyright]
stubPath = "server/typings"
typeCheckingMode = "strict"
reportUnknownVariableType = false
reportUnknownMemberType = false
reportMissingTypeStubs = false
reportPrivateUsage = false
