[project]
name = "llm-api"
version = "0.1.0"
description = "A fast CPU-based API for LLMs"
requires-python = ">=3.13.7, <3.14"
dependencies = [
    "ctranslate2>=4.6.0",
    "granian>=2.5.4",
    "jinja2>=3.1.6",
    "litestar>=2.17.0",
    "msgspec>=0.19.0",
    "pydantic-settings>=2.11.0",
    "transformers>=4.56.2",
    "uvloop>=0.21.0",
    "picologging>=0.9.3; python_version < '3.13'",
    "prometheus-client>=0.23.1",
    "aiohttp>=3.12.15",
    "opentelemetry-instrumentation-asgi>=0.58b0",
    "opentelemetry-exporter-otlp-proto-http>=1.37.0",
]

[project.optional-dependencies]
cuda = ["nvidia-cublas-cu12>=12.9.1.4"]

[dependency-groups]
dev = ["nodejs-wheel-binaries>=22.20.0", "pyright>=1.1.406", "ruff>=0.13.3"]

[project.scripts]
llm-api = "server:main"

[tool.uv]
package = true

[tool.ruff]
line-length = 120

[tool.ruff.lint]
select = ["ALL"]
ignore = ["D", "TC", "PLC0414", "INP001", "S104", "PYI001", "COM812", "PLR0913"]

[tool.ruff.lint.flake8-annotations]
suppress-dummy-args = true

[tool.pyright]
stubPath = "server/typings"
typeCheckingMode = "strict"
reportUnknownVariableType = false
reportUnknownMemberType = false
reportMissingTypeStubs = false
reportPrivateUsage = false
